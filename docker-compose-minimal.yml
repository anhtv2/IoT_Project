version: "3"
services:
  kafka1:
    image: confluentinc/cp-kafka
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_NODE_ID: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka1:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:19092'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  postgres:
    image: postgres:16.0-alpine
    container_name: postgres
    env_file:
      - db.env
    ports:
      - "5432:5432"
    volumes:
      - .\.db_data:/var/lib/postgresql/data
      - .\init.sql:/tmp/sql/init.sql
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready", "-U", "postgres" ]
      interval: 10s
      timeout: 10s
      retries: 5

  kafka-connect:
    image: confluentinc/cp-kafka-connect
    container_name: kafka-connect
    depends_on:
      - kafka1
      - postgres
    ports:
      - "8089:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka1:29092"
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-status
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components/,/connectors/"
    volumes:
      - .\connectors:/connectors

  streaming:
    image: anhaitrinh/smart-parking-system-stream-processing:latest
    ports:
      - "4040:4040"
    env_file:
      - streaming.env
    container_name: streaming
    depends_on:
      - kafka-connect
      - spark-master

  mqtt-proxy:
    image: confluentinc/cp-kafka-mqtt
    container_name: mqtt-proxy
    ports:
      - "1883:1883"
    environment:
      KAFKA_MQTT_BOOTSTRAP_SERVERS: "kafka1:29092"
      KAFKA_MQTT_TOPIC_REGEX_LIST: "sensors:sensors*"
      KAFKA_MQTT_CONFLUENT_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - kafka1

  app:
    image: anhaitrinh/smart-parking-system-backend:latest
    container_name: app
    env_file:
      - app.env
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - .\.redis_data:/data

  serving-layer:
    image: anhaitrinh/serving-layer:latest
    container_name: serving-layer
    ports:
      - "8001:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      kafka1:
        condition: service_started
    env_file:
      - serve.env

  cache:
    image: redis:alpine
    container_name: cache
    ports:
      - "6380:6379"

volumes:
  .db_data:
  .redis_data:
  connectors: