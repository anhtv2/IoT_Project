version: "3"
services:
  kafka1:
    image: confluentinc/cp-kafka
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_NODE_ID: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka1:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:19092,2@kafka2:19093,3@kafka3:19094'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100

  kafka2:
    image: confluentinc/cp-kafka
    container_name: kafka2
    ports:
      - "9093:9093"
    environment:
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_NODE_ID: 2
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://0.0.0.0:9093,CONTROLLER://kafka2:19093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:19092,2@kafka2:19093,3@kafka3:19094'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100

  kafka3:
    image: confluentinc/cp-kafka
    container_name: kafka3
    ports:
      - "9094:9094"
    environment:
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_NODE_ID: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LISTENERS: PLAINTEXT://kafka3:29094,PLAINTEXT_HOST://0.0.0.0:9094,CONTROLLER://kafka3:19094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:19092,2@kafka2:19093,3@kafka3:19094'
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100


  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8084:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

  postgres:
    image: postgres:16.0-alpine
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: app
      POSTGRES_PASSWORD: password
      POSTGRES_DB: app
    ports:
      - "5432:5432"
    volumes:
      - .\postgres:/var/lib/postgresql/data
      - .\init.sql:/tmp/sql/init.sql

#  kafka-source-connect:
#    image: confluentinc/cp-kafka-connect
#    container_name: kafka-source-connect
#    depends_on:
#      - kafka1
#      - kafka2
#      - kafka3
#      - postgres
#    ports:
#      - "8089:8083"
#    environment:
#      CONNECT_BOOTSTRAP_SERVERS: "kafka1:29092,kafka2:29093,kafka3:29094"
#      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-source-connect'
#      CONNECT_REST_PORT: 8083
#      CONNECT_GROUP_ID: kafka-source-connect
#      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-source-connect-configs
#      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-source-connect-offsets
#      CONNECT_STATUS_STORAGE_TOPIC: _kafka-source-connect-status
#      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
#      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
#      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components/,/connectors/"
#    volumes:
#      - .\connectors:/connectors

  kafka-sink-connect:
    image: confluentinc/cp-kafka-connect
    container_name: kafka-sink-connect
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - postgres
    ports:
      - "8090:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka1:29092,kafka2:29093,kafka3:29094"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-sink-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-sink-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-sink-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-sink-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-sink-connect-status
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components/,/connectors/"
    volumes:
      - .\connectors:/connectors

  streaming:
    build:
      context: streaming
      dockerfile: Dockerfile
    ports:
      - "4040:4040"
    environment:
      - KAFKA_BROKERS=kafka1:29092,kafka2:29093,kafka3:29094
      - DB_URL=jdbc:postgresql://postgres:5432/app
      - DB_USER=app
      - DB_PASSWORD=password
    container_name: streaming
    depends_on:
      - kafka-sink-connect
#      - kafka-source-connect
      - spark-master

#  mqtt-proxy:
#    image: confluentinc/cp-kafka-mqtt
#    container_name: mqtt-proxy
#    ports:
#      - "1883:1883"
#    environment:
#      KAFKA_MQTT_BOOTSTRAP_SERVERS: "kafka1:29092,kafka2:29093,kafka3:29094"
#      KAFKA_MQTT_TOPIC_REGEX_LIST: "sensors:sensors*"
#    depends_on:
#      - kafka1
#      - kafka2
#      - kafka3
  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"